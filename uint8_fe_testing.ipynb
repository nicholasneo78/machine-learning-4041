{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "253tsPfvV0QW"
   },
   "source": [
    "## Importing the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FbFZpsrNTore",
    "outputId": "0bdd05ac-9951-46d2-ad89-c49c9b0a5062"
   },
   "outputs": [],
   "source": [
    "# # connect to google colab\n",
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IX_NtAYKmT9I"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_1DvGKYtT_b2"
   },
   "outputs": [],
   "source": [
    "# import all the necessary model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import os\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, BatchNormalization, Activation, Dropout, Lambda, Input, GlobalAveragePooling2D, BatchNormalization, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "# from keras import regularizers\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "\n",
    "from IPython.display import display, Image\n",
    "import time\n",
    "\n",
    "#from tensorflow.keras.applications import Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "iIiKGRFtVJKf"
   },
   "outputs": [],
   "source": [
    "# change colab flag to false if train using jupyter notebook else set to true if using colab\n",
    "COLAB_FLAG = False\n",
    "\n",
    "COLAB_FILEPATH = './drive/My Drive/4041-dog-breed-classification/' if COLAB_FLAG == True else './'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nR35MV_brORV",
    "outputId": "83ea5ae8-47d7-482f-a555-1a223e84a656"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device:/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# checking if GPU is being used for training\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "if tf.test.gpu_device_name(): \n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"GPU is not detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nkfpvMCVV8sd"
   },
   "source": [
    "## Import the numpy (.npz) file consisting our training images\n",
    "* [np.save()](https://numpy.org/doc/stable/reference/generated/numpy.save.html)\n",
    "* [np.savez()](https://numpy.org/doc/stable/reference/generated/numpy.savez.html)\n",
    "* [np.savez_compressed()](https://numpy.org/doc/stable/reference/generated/numpy.savez_compressed.html)\n",
    "* [np.lib.format](https://numpy.org/doc/stable/reference/generated/numpy.lib.format.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pPExIcVPWx4l",
    "outputId": "6e98d71e-5954-4623-ce47-0d81f9d13518"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Datasets/preprocessed_data_u299x299.npz\n"
     ]
    }
   ],
   "source": [
    "INPUT_SHAPE = (299,299,3)\n",
    "# NPZ_PATH = f'{COLAB_FILEPATH}Datasets/preprocessed_data_{INPUT_SHAPE[0]}x{INPUT_SHAPE[1]}.npz'\n",
    "NPZ_PATH = f'{COLAB_FILEPATH}Datasets/preprocessed_data_u{INPUT_SHAPE[0]}x{INPUT_SHAPE[1]}.npz'\n",
    "print(NPZ_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "oeNBj_eZYOvG"
   },
   "outputs": [],
   "source": [
    "# check the numpy array information and the size conversion\n",
    "def convert_size(size_bytes):\n",
    "    if size_bytes == 0:\n",
    "        return \"0B\"\n",
    "    size_name = (\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\")\n",
    "    i = int(math.floor(math.log(size_bytes, 1024)))\n",
    "    p = math.pow(1024, i)\n",
    "    s = round(size_bytes / p, 2)\n",
    "    return \"%s %s\" % (s, size_name[i])\n",
    "\n",
    "def nparray_info(header, nparr):\n",
    "    print(header)\n",
    "    print(\"-  shape\\t\", nparr.shape)\n",
    "    print(\"-  dtype\\t\", nparr.dtype)\n",
    "    print(\"- nbytes\\t\", f\"{nparr.nbytes} ({convert_size(nparr.nbytes)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uXhSwln-WB00",
    "outputId": "07015891-da83-4b58-829e-d190ed2c4cda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from npz file\n",
      "['X', 'Y']\n",
      "Time taken to load compressed data: 13.066060543060303\n"
     ]
    }
   ],
   "source": [
    "# loading the npz file\n",
    "import gc\n",
    "print(\"Loading from npz file\")\n",
    "t = time.time()\n",
    "loaded = np.load(NPZ_PATH)\n",
    "print(loaded.files)\n",
    "loaded_X = loaded[\"X\"]\n",
    "loaded_Y = loaded[\"Y\"]\n",
    "del loaded\n",
    "gc.collect()\n",
    "\n",
    "print(f'Time taken to load compressed data: {time.time()-t}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uKiKuQciYAlO",
    "outputId": "fd1bd136-9afc-458e-d76f-f6f16b149b0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images (npz)\n",
      "-  shape\t (10222, 299, 299, 3)\n",
      "-  dtype\t uint8\n",
      "- nbytes\t 2741571066 (2.55 GB)\n",
      "\n",
      "Labels (npz)\n",
      "-  shape\t (10222, 120)\n",
      "-  dtype\t uint8\n",
      "- nbytes\t 1226640 (1.17 MB)\n"
     ]
    }
   ],
   "source": [
    "# print out shape, dtype and data size\n",
    "nparray_info(\"Images (npz)\", loaded_X)\n",
    "print()\n",
    "nparray_info(\"Labels (npz)\", loaded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mXN6XrmNYl5k",
    "outputId": "336248a1-5d87-4d8f-efd0-c9cac43b16b6"
   },
   "outputs": [],
   "source": [
    "# check the numpy array values whether is it normalised or not\n",
    "# loaded_X[50][0][:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "haoMGfI1ZJHt",
    "outputId": "931bb406-8575-449e-8ad5-d3091b1c2c4a"
   },
   "outputs": [],
   "source": [
    "# loaded_Y[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tU8d36M6b-Bw",
    "outputId": "79525f32-cf88-492f-94b6-4de954e40303"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape\t\t: (10222, 3)\n",
      "Unique labels\t: 120\n"
     ]
    }
   ],
   "source": [
    "# get the respective labels\n",
    "# loading labels from csv file\n",
    "df = pd.read_csv(f\"{COLAB_FILEPATH}Datasets/labels.csv\")\n",
    "\n",
    "# create dictionary of unique breeds with its respective id\n",
    "breeds = sorted(df.breed.unique())\n",
    "dict_breeds = dict(zip(breeds, range(len(breeds))))\n",
    "\n",
    "# add duplicate column\n",
    "df[\"breed_id\"] = df.breed\n",
    "# convert duplicated column as unique id\n",
    "df = df.replace({\"breed_id\":dict_breeds})\n",
    "\n",
    "print(\"Shape\\t\\t: {}\".format(df.shape))\n",
    "print(\"Unique labels\\t: {}\".format(len(breeds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6OzTowjRjs9g",
    "outputId": "df5c0980-8113-4d5a-818d-9fae4481657a"
   },
   "outputs": [],
   "source": [
    "# dict_breeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "xiVltZ5DZQht",
    "outputId": "454ad960-f7a0-4ebf-a18c-1c7bddea0b3b"
   },
   "outputs": [],
   "source": [
    "# # check the data\n",
    "# N = 20\n",
    "\n",
    "# plt.figure(figsize=(20,20))\n",
    "# for i in range(N):\n",
    "#     ax = plt.subplot(int(N/5),5,i+1)\n",
    "#     plt.title(breeds[np.where(loaded_Y[i]==1)[0][0]])\n",
    "#     if loaded_X.dtype==np.uint8:\n",
    "#         plt.imshow(loaded_X[i])\n",
    "#     else:\n",
    "#         plt.imshow(loaded_X[i].astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mzmVas2kZXrE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uK9iTRxqpa51"
   },
   "source": [
    "## Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "d_v9ey1qpoea"
   },
   "outputs": [],
   "source": [
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode = \"nearest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lu59CHDZpqoW"
   },
   "source": [
    "# --- MODEL BUILDING ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "u6pQoee41FBt"
   },
   "outputs": [],
   "source": [
    "# load the different pre-trained models\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.applications import VGG16, VGG19\n",
    "from tensorflow.keras.applications import ResNet50, ResNet101, ResNet152, ResNet50V2, ResNet101V2, ResNet152V2\n",
    "from tensorflow.keras.applications import InceptionV3, InceptionResNetV2\n",
    "from tensorflow.keras.applications import MobileNet, MobileNetV2\n",
    "from tensorflow.keras.applications import DenseNet121, DenseNet169, DenseNet201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "SOG76ddP8TQh"
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    # pre-processing layer\n",
    "    input_layer = Input(INPUT_SHAPE)\n",
    "    preprocessor = Lambda(lambda x: x/255.0, name=\"preprocessor\")(input_layer)\n",
    "    base = Xception(include_top=False,\n",
    "                    weights=\"imagenet\", \n",
    "                    input_shape=INPUT_SHAPE)(preprocessor)\n",
    "    # rebuild output layer\n",
    "    x = base\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    model = Model(inputs=input_layer, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
      "_________________________________________________________________\n",
      "preprocessor (Lambda)        (None, 299, 299, 3)       0         \n",
      "_________________________________________________________________\n",
      "xception (Functional)        (None, 10, 10, 2048)      20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "=================================================================\n",
      "Total params: 20,861,480\n",
      "Trainable params: 20,806,952\n",
      "Non-trainable params: 54,528\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = build_model()\n",
    "feature_extractor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 42s 107ms/step\n"
     ]
    }
   ],
   "source": [
    "features = feature_extractor.predict(loaded_X, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image size (299, 299, 3)\n",
      "features\n",
      "-  shape\t (10222, 2048)\n",
      "-  dtype\t float32\n",
      "- nbytes\t 83738624 (79.86 MB)\n"
     ]
    }
   ],
   "source": [
    "print(\"image size\", INPUT_SHAPE)\n",
    "nparray_info(\"features\", features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features2 = feature_extractor.predict(train_datagen.flow(loaded_X,loaded_Y,batch_size=64,shuffle=True), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "53BxdHX1W94B"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3f-hofJ9u9-4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5yHHFTHtW96O"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "training-general-128.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
