{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import necessary library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for garbage collection\n",
    "import gc\n",
    "\n",
    "# for warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# utility libraries\n",
    "import os\n",
    "import copy\n",
    "import tqdm\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import cv2, random, time, shutil, csv\n",
    "import tensorflow as tf \n",
    "import math\n",
    "import time\n",
    "from util import *\n",
    "\n",
    "# keras libraries\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import load_img, ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import BatchNormalization, Dense, GlobalAveragePooling2D, Lambda, Dropout, InputLayer, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device:/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# checking if GPU is being used for training\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "if tf.test.gpu_device_name(): \n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"GPU is not detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare of data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape\t\t: (10222, 2)\n",
      "Unique labels\t: 120\n"
     ]
    }
   ],
   "source": [
    "# loading labels from csv file\n",
    "data_dir = os.path.join(os.getcwd(), 'Datasets')\n",
    "data_df = pd.read_csv(os.path.join(data_dir, 'labels.csv'))\n",
    "breeds = sorted(data_df.breed.unique())\n",
    "\n",
    "print(f\"Shape\\t\\t: {data_df.shape}\")\n",
    "print(f\"Unique labels\\t: {len(breeds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "img_size = 299\n",
    "batch_size=128\n",
    "epochs=80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images data\n",
    "def loadData():\n",
    "    images_list = sorted(os.listdir(os.path.join(data_dir, 'train')))\n",
    "    X = []\n",
    "    Y = []\n",
    "    for image in tqdm.tqdm(images_list):\n",
    "        # find matching label\n",
    "        breed = data_df[data_df['id'] == image[:-4]].iloc[0,1]\n",
    "        breed_index = int(breeds.index(breed)) \n",
    "\n",
    "        # reading image data\n",
    "        image_path = os.path.join(data_dir, 'train', image)\n",
    "        res_image = load_img(image_path, target_size=(img_size, img_size))\n",
    "        res_image = np.asarray(res_image)\n",
    "        X.append(res_image)\n",
    "        Y.append(breed_index)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 10222/10222 [01:02<00:00, 164.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to allocate 2.55 GiB for an array with shape (10222, 299, 299, 3) and data type uint8\n",
      "Time taken: 65.90514922142029\n"
     ]
    }
   ],
   "source": [
    "saving_path = os.path.join(data_dir, f'data_resized{img_size}x{img_size}.h5')\n",
    "\n",
    "\n",
    "t = time.time()\n",
    "if (os.path.isfile(saving_path)):\n",
    "    X, Y = load_h5_data(saving_path)\n",
    "else:\n",
    "    X, Y = loadData()\n",
    "    generate_h5_data(X, Y, saving_path)\n",
    "print(f'Time taken: {time.time()-t}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10222 10222\n",
      "(10222, 224, 224, 3) (10222, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "143"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting to arrays\n",
    "print(len(X), len(Y))\n",
    "assert(len(X)==len(Y))\n",
    "Xarr = np.array(X)\n",
    "Yarr = np.array(Y).reshape(-1,1)\n",
    "\n",
    "del(X)\n",
    "print(Xarr.shape, Yarr.shape)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Xarr\n",
      "-  shape\t (10222, 224, 224, 3)\n",
      "-  dtype\t uint8\n",
      "- nbytes\t 1538697216 (1.43 GB)\n",
      "\n",
      "Yarr\n",
      "-  shape\t (10222, 1)\n",
      "-  dtype\t int32\n",
      "- nbytes\t 40888 (39.93 KB)\n"
     ]
    }
   ],
   "source": [
    "# print out shape, dtype and data size\n",
    "nparray_info(\"\\nXarr\", Xarr)\n",
    "nparray_info(\"\\nYarr\", Yarr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10222, 224, 224, 3) (10222, 120)\n"
     ]
    }
   ],
   "source": [
    "# converting labels to one hot\n",
    "Yarr_hot = to_categorical(Y)\n",
    "print(Xarr.shape, Yarr_hot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE EXTRACTION OF TRAINING ARRAYS\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "def get_features(model_name, data_preprocessor, data):\n",
    "    '''\n",
    "    1- Create a feature extractor to extract features from the data.\n",
    "    2- Returns the extracted features and the feature extractor.\n",
    "    '''\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(data)\n",
    "\n",
    "\n",
    "    def preprocess(x):\n",
    "        x = tf.image.random_flip_left_right(x)\n",
    "        x = tf.image.random_brightness(x, 0.5)\n",
    "        return x\n",
    "\n",
    "    ds = dataset.map(preprocess, num_parallel_calls=AUTO).batch(64)\n",
    "\n",
    "    input_size = data.shape[1:]\n",
    "    #Prepare pipeline.\n",
    "    input_layer = Input(input_size)\n",
    "    preprocessor = Lambda(data_preprocessor)(input_layer)\n",
    "\n",
    "    base_model = model_name(weights='imagenet', include_top=False,\n",
    "                                input_shape=input_size)(preprocessor)\n",
    "\n",
    "    avg = GlobalAveragePooling2D()(base_model)\n",
    "    feature_extractor = Model(inputs = input_layer, outputs = avg)\n",
    "\n",
    "\n",
    "    #Extract feature.\n",
    "    feature_maps = feature_extractor.predict(ds, verbose=1)\n",
    "    nparray_info(\"Feature maps\", feature_maps)\n",
    "    \n",
    "    # deleting variables\n",
    "    del(feature_extractor, base_model, preprocessor, dataset)\n",
    "    gc.collect()\n",
    "    return feature_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE EXTRACTION OF VALIDAION AND TESTING ARRAYS\n",
    "def get_valfeatures(model_name, data_preprocessor, data):\n",
    "    '''\n",
    "    Same as above except not image augmentations applied.\n",
    "    Used for feature extraction of validation and testing.\n",
    "    '''\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(data)\n",
    "\n",
    "    ds = dataset.batch(64)\n",
    "\n",
    "    input_size = data.shape[1:]\n",
    "    #Prepare pipeline.\n",
    "    input_layer = Input(input_size)\n",
    "    preprocessor = Lambda(data_preprocessor)(input_layer)\n",
    "\n",
    "    base_model = model_name(weights='imagenet', include_top=False, input_shape=input_size)(preprocessor)\n",
    "\n",
    "    avg = GlobalAveragePooling2D()(base_model)\n",
    "    feature_extractor = Model(inputs = input_layer, outputs = avg)\n",
    "    #Extract feature.\n",
    "    feature_maps = feature_extractor.predict(ds, verbose=1)\n",
    "    nparray_info(\"Feature maps\", feature_maps)\n",
    "    return feature_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate feature dictionary \n",
    "def generate_model_features(feat_func, model_names, models, preprocs, array):\n",
    "    print(f\"Beggining extraction with {feat_func.__name__}\\n\")\n",
    "    feats_dict = {}\n",
    "\n",
    "    for i in range(len(models)):\n",
    "        print(f\"\\nStarting feature extraction with {models[i].__name__} using {preprocs[i].__name__}\\n\")\n",
    "        # applying the above function and storing in list\n",
    "        feats_dict[model_names[i]] = feat_func(models[i], preprocs[i], array)\n",
    "        \n",
    "    # memory saving\n",
    "    del(array)\n",
    "    gc.collect()\n",
    "    return feats_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RETURNING CONCATENATED FEATURES\n",
    "def get_concat_features(model_names, feats_dict):\n",
    "    feats_list = []\n",
    "    \n",
    "    for name in model_names:\n",
    "        print(f\"collect features for {name}...\")\n",
    "        feats_list.append( feats_dict[name] )\n",
    "\n",
    "    # features concatenating\n",
    "    final_feats = np.concatenate(feats_list, axis=-1)\n",
    "    # memory saving\n",
    "    del(feats_list)\n",
    "    gc.collect()\n",
    "    return final_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINING models and preprocessors imports\n",
    "from tensorflow.keras.applications.xception import Xception, preprocess_input\n",
    "xception_preprocessor = preprocess_input\n",
    "from tensorflow.keras.applications.densenet import DenseNet169, preprocess_input\n",
    "densenet_preprocessor = preprocess_input\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "inc_resnet_preprocessor = preprocess_input\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet, preprocess_input \n",
    "mobilenet_preprocessor = preprocess_input\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "inception_preprocessor = preprocess_input\n",
    "from tensorflow.keras.applications.resnet import ResNet50, preprocess_input\n",
    "restnet_preprocessor = preprocess_input\n",
    "\n",
    "\n",
    "# collecting top 6 models' features for evaluation later\n",
    "model_names = [\"Xception\", \"DenseNet169\", \"InceptionResNetV2\", \"MobileNet\", \"InceptionV3\", \"RestNet50\"]\n",
    "models = [Xception, DenseNet169, InceptionResNetV2, MobileNet, InceptionV3, ResNet50 ]\n",
    "preprocs = [xception_preprocessor, densenet_preprocessor, inc_resnet_preprocessor, \n",
    "            mobilenet_preprocessor, inception_preprocessor, restnet_preprocessor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform feature extraction and save as h5 file\n",
    "saving_path = os.path.join(data_dir, f'features.h5')\n",
    "\n",
    "t = time.time()\n",
    "# feats_dict = {}\n",
    "if (os.path.isfile(saving_path)):\n",
    "    feats_dict = load_features_data(saving_path)\n",
    "else:\n",
    "    feats_dict = generate_model_features(get_features, model_names, models, preprocs, Xarr)\n",
    "    generate_features_data(feats_dict, saving_path)\n",
    "gc.collect()\n",
    "print(f'Time taken: {time.time()-t}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in feats_dict:\n",
    "    nparray_info(name, feats_dict[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect features of from dict\n",
    "train_models = [model_names[i] for i in range(3)]    # can replace range to [0,1,2]\n",
    "final_train_features = get_concat_features(train_models, feats_dict)\n",
    "\n",
    "gc.collect()\n",
    "nparray_info(\"Final feature maps\", final_train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "EarlyStop_callback = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True, verbose=0)\n",
    "\n",
    "my_callback=[EarlyStop_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "# Use K fold of 5, to ensure train:validation is 80:20\n",
    "splits = list(StratifiedKFold(n_splits=5, shuffle=True, random_state=10).split(final_train_features, Y))\n",
    "\n",
    "trained_models = []\n",
    "val_accuracy = []\n",
    "val_losses = []\n",
    "train_accuracy = []\n",
    "train_losses = []\n",
    "\n",
    "#Prepare And Train DNN model\n",
    "for i, (train_idx, valid_idx) in enumerate(splits): \n",
    "\n",
    "    print(f\"\\nStarting fold {i+1}\\n\")\n",
    "    x_train_fold = final_train_features[train_idx, :]\n",
    "    y_train_fold = Yarr_hot[train_idx, :]\n",
    "    x_val_fold = final_train_features[valid_idx]\n",
    "    y_val_fold = Yarr_hot[valid_idx, :]\n",
    "\n",
    "    dnn = keras.models.Sequential([\n",
    "        InputLayer(final_train_features.shape[1:]),\n",
    "        Dropout(0.7),\n",
    "        Dense(120, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    dnn.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    print(\"Training...\")\n",
    "    #Train simple DNN on extracted features.\n",
    "    h = dnn.fit(x_train_fold, y_train_fold,\n",
    "                batch_size=batch_size,\n",
    "                epochs=epochs,\n",
    "                verbose=0,\n",
    "                validation_data = (x_val_fold, y_val_fold),\n",
    "                callbacks=my_callback)\n",
    "    print(\"Evaluating model ...\")\n",
    "    model_res_val = dnn.evaluate(x_val_fold, y_val_fold)\n",
    "    model_res_train = dnn.evaluate(x_train_fold, y_train_fold)\n",
    "    train_accuracy.append(model_res_train[1])\n",
    "    train_losses.append(model_res_train[0])\n",
    "    val_accuracy.append(model_res_val[1])\n",
    "    val_losses.append(model_res_val[0])\n",
    "    trained_models.append(dnn)\n",
    "    plot_model_history(h, saving_name=f\"fold_{i+1}_LA\")\n",
    "    \n",
    "\n",
    "print('\\n CV Score -')\n",
    "print(f\"\\nTrainAccuracy - avg:{sum(train_accuracy)/len(train_accuracy)}, max:{max(train_accuracy)}\")\n",
    "print(f\"\\nTrainLoss - avg:{sum(train_losses)/len(train_losses)}, min:{min(train_losses)}\")\n",
    "print(f\"\\nValAccuracy - avg:{sum(val_accuracy)/len(val_accuracy)}, max:{max(val_accuracy)}\")\n",
    "print(f\"\\nValLoss - avg:{sum(val_losses)/len(val_losses)}, min:{min(val_losses)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TEST IMAGES\n",
    "# test_images_list = sorted(os.listdir(os.path.join(data_dir, 'test')))\n",
    "# X = []\n",
    "# i = 0\n",
    "# for image in tqdm.tqdm(test_images_list):\n",
    "\n",
    "#     image_path = os.path.join(data_dir, 'test',image)\n",
    "#     orig_image = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
    "#     res_image = cv2.resize(orig_image,(img_size, img_size))\n",
    "#     X.append(res_image)\n",
    "#     i+=1\n",
    "\n",
    "# Xtesarr = np.array(X)\n",
    "\n",
    "# del(X)\n",
    "# gc.collect()\n",
    "\n",
    "# Xtesarr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # FEATURE EXTRACTION OF TEST IMAGES\n",
    "# test_features = get_concat_features(get_valfeatures, models, preprocs, Xtesarr)\n",
    "\n",
    "# del(Xtesarr)\n",
    "# gc.collect()\n",
    "# print('Final feature maps shape', test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_norm = trained_models[0].predict(test_features, batch_size=128)/3\n",
    "# for dnn in trained_models[1:]:\n",
    "#     y_pred_norm += dnn.predict(test_features, batch_size=128)/3\n",
    "\n",
    "# y_pred_norm.shape\n",
    "\n",
    "# df.iloc[:, 1:] = y_pred_norm\n",
    "# df.to_csv('submission.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
