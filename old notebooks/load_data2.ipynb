{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "owned-mobile",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from shutil import copyfile\n",
    "\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "small-center",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape\t\t: (10222, 3)\n",
      "Unique labels\t: 120\n"
     ]
    }
   ],
   "source": [
    "# loading labels from csv file\n",
    "df = pd.read_csv(\"Datasets/labels.csv\")\n",
    "\n",
    "# create dictionary of unique breeds with its respective id\n",
    "breeds = df.breed.unique()\n",
    "dict_breeds = dict(zip(breeds, range(len(breeds))))\n",
    "\n",
    "# add duplicate column\n",
    "df[\"breed_id\"] = df.breed\n",
    "# convert duplicated column as unique id\n",
    "df = df.replace({\"breed_id\":dict_breeds})\n",
    "\n",
    "print(\"Shape\\t\\t: {}\".format(df.shape))\n",
    "print(\"Unique labels\\t: {}\".format(len(breeds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "tired-smell",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_TRAIN    = \"images/train/\"\n",
    "DIR_VALIDATE = \"images/validation/\"\n",
    "\n",
    "def move_files(files, dist_folder=\"image/train/\"):\n",
    "    for src_file_path in files:\n",
    "        # read file info\n",
    "        file_name = os.path.basename(src_file_path)\n",
    "        img_id    = file_name.split(\".\")[0]\n",
    "        result    = df.loc[df['id'] == img_id]\n",
    "        if result.empty:\n",
    "            print(\"LABEL NOT FOUND: {}\".format(img_id))\n",
    "            continue\n",
    "        label = result.iloc[0][\"breed\"]\n",
    "        \n",
    "        # create new folder structure\n",
    "        dist_file_path = dist_folder+label+\"/\"+file_name\n",
    "        os.makedirs(os.path.dirname(dist_file_path), exist_ok=True)\n",
    "        copyfile(src_file_path, dist_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "south-drill",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10222 files found!\n",
      "#train:  7155\n",
      "#val:  3067\n"
     ]
    }
   ],
   "source": [
    "# search all files in directory\n",
    "files = [f for f in glob.glob(\"Datasets/train\" + \"/**/*\", recursive=True) if not os.path.isdir(f)]\n",
    "print(\"{} files found!\".format(len(files)))\n",
    "\n",
    "\n",
    "# spliting the files in train and validation sets\n",
    "random.seed(42)\n",
    "random.shuffle(files)\n",
    "train, validate = np.split(files, [int(len(files)*0.7)])\n",
    "print(\"#train: \",len(train))\n",
    "print(\"#val: \",len(validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-turning",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "idx = 0\n",
    "img_path = files[idx]\n",
    "img_file = os.path.basename(img_path)\n",
    "img_id   = img_file.split(\".\")[0]\n",
    "result   = df.loc[df['id'] == img_id]\n",
    "label    = result.iloc[0][\"breed\"]\n",
    "#result.at[0,'breed']\n",
    "\n",
    "print(img_path)\n",
    "print(img_file)\n",
    "print(img_id)\n",
    "print(label)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ordinary-maryland",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(os.getcwd(), 'Images')):\n",
    "    move_files(train,    DIR_TRAIN)\n",
    "    move_files(validate, DIR_VALIDATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-cyprus",
   "metadata": {},
   "source": [
    "# Test on training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "proprietary-mouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, Flatten, Dropout, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "coupled-shape",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device:/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# checking if GPU is being used for training\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "if tf.test.gpu_device_name(): \n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"GPU is not detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "grand-budget",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters \n",
    "epochs = 30\n",
    "lr = 1e-3\n",
    "batch_size = 32\n",
    "img_dims = (128,128,3)\n",
    "keep_pretrained = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "divided-retrieval",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7155 images belonging to 120 classes.\n",
      "Found 3067 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode = \"nearest\"\n",
    ")\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        DIR_TRAIN,  # this is the target directory\n",
    "        target_size=(img_dims[0], img_dims[1]),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical') \n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        DIR_VALIDATE,\n",
    "        target_size=(img_dims[0], img_dims[1]),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-trader",
   "metadata": {},
   "source": [
    "## checking input size\n",
    "```python\n",
    "print(\"#img:\",train_generator.samples)\n",
    "print(\"#steps per epochs:\",train_generator.samples// batch_size)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-lemon",
   "metadata": {},
   "source": [
    "## Using Preprocessing for model\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode = \"nearest\",\n",
    "    preprocessing_function = preprocess_input\n",
    ")\n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function = preprocess_input\n",
    ")\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        DIR_TRAIN,\n",
    "        target_size=(img_dims[0], img_dims[1]), \n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical') \n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        DIR_VALIDATE,\n",
    "        target_size=(img_dims[0], img_dims[1]),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "unavailable-parent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# trainable\t: 21052832\n",
      "# non-trainable\t: 54528\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import Xception\n",
    "\n",
    "model_name = \"Xception_s{}x{}_bs{}_e{}_w{}\".format(img_dims[0], img_dims[1], batch_size, epochs, \"Keep\" if keep_pretrained else \"NoKeep\")\n",
    "\n",
    "# retrieve base model\n",
    "base = Xception(include_top=False, weights='imagenet', input_shape=img_dims)\n",
    "\n",
    "# freeze pre-trained weight\n",
    "if (keep_pretrained):\n",
    "    base.trainable = False\n",
    "\n",
    "# rebuild output layer\n",
    "x = base.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "head = Dense(120, activation='softmax')(x)\n",
    "model = Model(inputs=base.input, outputs=head)\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(optimizer=Adam(lr=lr), \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# validate with # trainable/non-trainable weights\n",
    "trainable_count = np.sum([K.count_params(w) for w in model.trainable_weights])\n",
    "non_trainable_count = np.sum([K.count_params(w) for w in model.non_trainable_weights])\n",
    "print(\"# trainable\\t: {}\".format(trainable_count))\n",
    "print(\"# non-trainable\\t: {}\".format(non_trainable_count))\n",
    "\n",
    "# start training models\n",
    "H=model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples// batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_generator.samples // batch_size\n",
    ")\n",
    "\n",
    "# plot model performance\n",
    "plot_model_history(H, saving_name=\"{}\".format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-capitol",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-feelings",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
