{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aging-preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import h5py\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import time\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "available-annotation",
   "metadata": {},
   "source": [
    "# loading data into np.array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "filled-brand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape\t\t: (10222, 3)\n",
      "Unique labels\t: 120\n"
     ]
    }
   ],
   "source": [
    "# loading labels from csv file\n",
    "df = pd.read_csv(\"Datasets/labels.csv\")\n",
    "\n",
    "# create dictionary of unique breeds with its respective id\n",
    "breeds = df.breed.unique()\n",
    "dict_breeds = dict(zip(breeds, range(len(breeds))))\n",
    "\n",
    "# add duplicate column\n",
    "df[\"breed_id\"] = df.breed\n",
    "# convert duplicated column as unique id\n",
    "df = df.replace({\"breed_id\":dict_breeds})\n",
    "\n",
    "print(\"Shape\\t\\t: {}\".format(df.shape))\n",
    "print(\"Unique labels\\t: {}\".format(len(breeds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "pediatric-melissa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters \n",
    "EPOCHS = 50\n",
    "LR = 1e-3\n",
    "BATCH_SIZE = 32\n",
    "INPUT_SHAPE = (64,64,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eight-headset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10222 files found!\n",
      "loading images\n",
      "Time taken to load images: 42.437124490737915\n",
      "pre-processing\n",
      "Time taken to pre-processing: 1.4311761856079102\n",
      "x_data shape: (10222, 64, 64, 3)\n",
      "y_data shape: (10222, 1)\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "labels = []\n",
    "\n",
    "# collect all files from directory into a list\n",
    "image_files_train = [f for f in glob.glob(\"Datasets/train\" + \"/**/*\", recursive=True) if not os.path.isdir(f)]\n",
    "print(\"{} files found!\".format(len(image_files_train)))\n",
    "\n",
    "# create groud-truth label from the image path\n",
    "print(\"loading images\")\n",
    "t = time.time()\n",
    "for img in image_files_train:\n",
    "    img_file = os.path.basename(img)\n",
    "    name = img_file.split(\".\")[0]\n",
    "\n",
    "    # check if image file has a record in given labels\n",
    "    result = df.loc[df['id'] == name]\n",
    "    if result.empty:\n",
    "        print(\"LABEL NOT FOUND: {}\".format(name))\n",
    "        continue\n",
    "    else:\n",
    "        # reading of image \n",
    "        image = cv2.imread(img)\n",
    "        image = cv2.resize(image, (INPUT_SHAPE[0], INPUT_SHAPE[1]))\n",
    "        image = img_to_array(image)\n",
    "        data.append(image)\n",
    "        # read respective unique breed id from result \n",
    "        label = result['breed_id'].iloc[0]\n",
    "        labels.append([label])\n",
    "print(f'Time taken to load images: {time.time()-t}')\n",
    "\n",
    "# pre-processing (normalisation)\n",
    "print(\"pre-processing\")\n",
    "t = time.time()\n",
    "data = np.array(data, dtype=np.float16) / 255.0\n",
    "labels = np.array(labels, dtype=np.uint8)\n",
    "print(f'Time taken to pre-processing: {time.time()-t}')\n",
    "\n",
    "print('x_data shape:', data.shape)\n",
    "print('y_data shape:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "better-unknown",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(labels, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "received-pendant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Info\n",
      "-  shape:\t (10222, 64, 64, 3)\n",
      "-  dtype:\t float16\n",
      "- nbytes:\t 251215872\n",
      "Y Info\n",
      "-  shape:\t (10222, 1)\n",
      "-  dtype:\t uint8\n",
      "- nbytes:\t 10222\n"
     ]
    }
   ],
   "source": [
    "# print out shape, dtype and data size\n",
    "print(\"X Info\")\n",
    "print(\"-  shape:\\t\", data.shape)\n",
    "print(\"-  dtype:\\t\", data.dtype)\n",
    "print(\"- nbytes:\\t\", data.nbytes)\n",
    "\n",
    "print(\"Y Info\")\n",
    "print(\"-  shape:\\t\", labels.shape)\n",
    "print(\"-  dtype:\\t\", labels.dtype)\n",
    "print(\"- nbytes:\\t\", labels.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-pierce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-jacket",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "appointed-district",
   "metadata": {},
   "source": [
    "### loading and saving with .npz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "iraqi-surrey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to save compressed data: 23.550722122192383\n"
     ]
    }
   ],
   "source": [
    "saving_name = \"preprocessed_data_{}x{}.npz\".format(INPUT_SHAPE[0], INPUT_SHAPE[1])\n",
    "\n",
    "t = time.time()\n",
    "np.savez_compressed(\"./Datasets/\"+saving_name, X=data, Y=labels)\n",
    "print(f'Time taken to save compressed data: {time.time()-t}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "threatened-moscow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X', 'Y']\n",
      "Time taken to load compressed data: 1.8103985786437988\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "loaded = np.load(\"./Datasets/\"+saving_name)\n",
    "print(loaded.files)\n",
    "loaded_X = loaded[\"X\"]\n",
    "loaded_Y = loaded[\"Y\"]\n",
    "print(f'Time taken to load compressed data: {time.time()-t}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-doctor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "extensive-samba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Info\n",
      "-  shape:\t (10222, 64, 64, 3)\n",
      "-  dtype:\t float16\n",
      "- nbytes:\t 251215872\n",
      "Y Info\n",
      "-  shape:\t (10222, 1)\n",
      "-  dtype:\t uint8\n",
      "- nbytes:\t 10222\n"
     ]
    }
   ],
   "source": [
    "print(\"X Info\")\n",
    "print(\"-  shape:\\t\", loaded_X.shape)\n",
    "print(\"-  dtype:\\t\", loaded_X.dtype)\n",
    "print(\"- nbytes:\\t\", loaded_X.nbytes)\n",
    "\n",
    "print(\"Y Info\")\n",
    "print(\"-  shape:\\t\", loaded_Y.shape)\n",
    "print(\"-  dtype:\\t\", loaded_Y.dtype)\n",
    "print(\"- nbytes:\\t\", loaded_Y.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cellular-cover",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure correctness of data\n",
    "assert labels.dtype == loaded_Y.dtype\n",
    "assert (labels==loaded_Y).all()\n",
    "\n",
    "\n",
    "assert data.dtype == loaded_X.dtype\n",
    "assert np.allclose(data, loaded_X)\n",
    "assert (data==loaded_X).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-deposit",
   "metadata": {},
   "source": [
    "### loading and saving with h5 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "forty-doubt",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_h5_data(data,labels,filename):\n",
    "    assert(type(filename) is str)\n",
    "    assert(len(data) == len(labels)) \n",
    "    try:\n",
    "        filepath= f'./{filename}.h5'\n",
    "        h5data = h5py.File(filepath, 'w')\n",
    "        h5data.create_dataset('image', data= data, compression=\"gzip\", compression_opts=9)\n",
    "        h5data['label'] = labels\n",
    "    finally:\n",
    "        h5data.close()\n",
    "        \n",
    "def load_h5_data(h5filepath):\n",
    "    h5file = h5py.File(h5filepath, \"r\")\n",
    "    try:\n",
    "        x_fieldname,y_fieldname, = h5file.keys()   #this order is Gfriend files\n",
    "        print(\"The keys are: \", h5file.keys())\n",
    "        data = np.array(h5file['image'][:]) # your test set features\n",
    "        labels = np.array(h5file['label'][:]) # your test set labels\n",
    "        print(\"The shape of x_field\",data.shape)\n",
    "        print(\"The shape of y_field\",labels.shape)\n",
    "    finally:\n",
    "        h5file.close()\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "incorporate-functionality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to save compressed data: 21.737980842590332\n"
     ]
    }
   ],
   "source": [
    "saving_name = \"preprocessed_data_{}x{}\".format(INPUT_SHAPE[0], INPUT_SHAPE[1])\n",
    "\n",
    "t = time.time()\n",
    "generate_h5_data(data, labels, saving_name)\n",
    "print(f'Time taken to save compressed data: {time.time()-t}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "perceived-daniel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from h5 file\n",
      "The keys are:  <KeysViewHDF5 ['image', 'label']>\n",
      "The shape of x_field (10222, 64, 64, 3)\n",
      "The shape of y_field (10222, 1)\n",
      "Time taken to load compressed data: 2.6273491382598877\n"
     ]
    }
   ],
   "source": [
    "print(\"loading from h5 file\")\n",
    "t = time.time()\n",
    "loaded_X, loaded_Y = load_h5_data(saving_name+\".h5\")\n",
    "print(f'Time taken to load compressed data: {time.time()-t}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "approximate-curtis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Info\n",
      "-  shape:\t (10222, 64, 64, 3)\n",
      "-  dtype:\t float16\n",
      "- nbytes:\t 251215872\n",
      "Y Info\n",
      "-  shape:\t (10222, 1)\n",
      "-  dtype:\t uint8\n",
      "- nbytes:\t 10222\n"
     ]
    }
   ],
   "source": [
    "print(\"X Info\")\n",
    "print(\"-  shape:\\t\", loaded_X.shape)\n",
    "print(\"-  dtype:\\t\", loaded_X.dtype)\n",
    "print(\"- nbytes:\\t\", loaded_X.nbytes)\n",
    "\n",
    "print(\"Y Info\")\n",
    "print(\"-  shape:\\t\", loaded_Y.shape)\n",
    "print(\"-  dtype:\\t\", loaded_Y.dtype)\n",
    "print(\"- nbytes:\\t\", loaded_Y.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "hungarian-mobility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure correctness of data\n",
    "assert labels.dtype == loaded_Y.dtype\n",
    "assert (labels==loaded_Y).all()\n",
    "\n",
    "\n",
    "assert data.dtype == loaded_X.dtype\n",
    "assert np.allclose(data, loaded_X)\n",
    "assert (data==loaded_X).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secondary-topic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-keeping",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
